# database/controller/ORM.py

import pandas as pd
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import inspect, text, select
from dotenv import load_dotenv
import functools
import re

from utils.seller_parcer_api import SellerParserAPI
from utils.logger import setup_logger
from database.entities.core import Database, Base
from database.entities.models import MPStatSeller

load_dotenv()
logger = setup_logger(__name__)

def session_manager(method):
    @functools.wraps(method)
    async def wrapper(self, *args, **kwargs):
        async with self.db.session() as session:
            async with session.begin():
                try:
                    result = await method(self, session, *args, **kwargs)
                    await session.commit()
                    logger.info(f"‚úÖ {method.__name__} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    return result
                except Exception as e:
                    await session.rollback()
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ {method.__name__}: {e}", exc_info=True)
                    raise e
    return wrapper

def clean_value(val, field=None):
    if pd.isna(val) or val == 'nan':
        return None
    if isinstance(val, pd.Timestamp):
        return val.to_pydatetime()
    if isinstance(val, str):
        if field and field in ("registration_date", "liquidation_date"):
            if re.search(r"[A-Za-z]{2,}", val):
                return None
            try:
                dt = pd.to_datetime(val, errors='raise')
                return dt.to_pydatetime()
            except Exception:
                return None
    return val

class SuppliersORM:
    def __init__(self, db: Database = Database()):
        self.db = db

    async def ensure_tables(self):
        async with self.db.async_engine.begin() as conn:
            def check_tables(sync_conn):
                sync_conn.execute(text("SET search_path TO public"))
                inspector = inspect(sync_conn)
                return inspector.get_table_names(schema="public")

            tables = await conn.run_sync(check_tables)

            if "suppliers" not in tables:
                logger.info("üìÇ –¢–∞–±–ª–∏—Ü–∞ 'suppliers' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞—ë–º...")
                await conn.run_sync(Base.metadata.create_all)
                logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ 'suppliers' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞")
            else:
                logger.info("üìÅ –¢–∞–±–ª–∏—Ü–∞ 'suppliers' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ")

    async def import_from_excel(self, df: pd.DataFrame, batch_size: int = 100):
        if "–ü—Ä–æ—Ñ–∏–ª—å –Ω–∞ —Å–∞–π—Ç–µ Wildberries" not in df.columns:
            logger.error("‚ùå –í —Ç–∞–±–ª–∏—Ü–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ '–ü—Ä–æ—Ñ–∏–ª—å –Ω–∞ —Å–∞–π—Ç–µ Wildberries'")
            return

        profile_column = "–ü—Ä–æ—Ñ–∏–ª—å –Ω–∞ —Å–∞–π—Ç–µ Wildberries"
        total = len(df)
        added, skipped = 0, 0

        for i in range(0, total, batch_size):
            chunk = df.iloc[i:i + batch_size]
            async with self.db.session() as session:
                existing_profiles = await self._get_existing_profiles(session, chunk[profile_column].tolist())

                new_objects = []
                for _, row in chunk.iterrows():
                    profile = clean_value(row.get(profile_column))
                    if profile in existing_profiles:
                        skipped += 1
                        continue

                    obj = Supplier(
                        inn=clean_value(row.get("–ò–ù–ù")),
                        wb_profile=profile,
                        seller_name=clean_value(row.get("–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥–∞–≤—Ü–∞")),
                        product_section=clean_value(row.get("–†–∞–∑–¥–µ–ª —Ç–æ–≤–∞—Ä–æ–≤")),
                        product_category=clean_value(row.get("–ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–æ–≤")),
                        items_sold=clean_value(row.get("–¢–æ–≤–∞—Ä–æ–≤ –ø—Ä–æ–¥–∞–Ω–æ")),
                        review_count=clean_value(row.get("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤")),
                        seller_rating=clean_value(row.get("–†–µ–π—Ç–∏–Ω–≥ –ø—Ä–æ–¥–∞–≤—Ü–∞")),
                        percent_purchased=clean_value(row.get("% –≤—ã–∫—É–ø–ª–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")),
                        registration_date=clean_value(row.get("–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–∞ Wildberries"), field="registration_date"),
                        legal_address=clean_value(row.get("–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å")),
                        phone_mobile=clean_value(row.get("–†–∞–±–æ—á–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã –º–æ–±–∏–ª—å–Ω—ã–µ")),
                        phone_city=clean_value(row.get("–†–∞–±–æ—á–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω—ã –≥–æ—Ä–æ–¥—Å–∫–∏–µ")),
                        email=clean_value(row.get("–†–∞–±–æ—á–∏–µ Email")),
                        email_alt=clean_value(row.get("–†–∞–±–æ—á–∏–µ Email –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫")),
                        website=clean_value(row.get("–°–∞–π—Ç")),
                        whatsapp=clean_value(row.get("Whatsapp")),
                        telegram=clean_value(row.get("Telegram")),
                        vk=clean_value(row.get("VK")),
                        instagram=clean_value(row.get("Instagram")),
                        ok=clean_value(row.get("OK")),
                        avg_sales_per_day=clean_value(row.get("–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–∞–≤–∞–µ–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –≤ –¥–µ–Ω—å")),
                        company_status=clean_value(row.get("–°—Ç–∞—Ç—É—Å –∫–æ–º–ø–∞–Ω–∏–∏")),
                        liquidation_date=clean_value(row.get("–î–∞—Ç–∞ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏"), field="liquidation_date")
                    )
                    new_objects.append(obj)

                session.add_all(new_objects)
                await session.commit()
                added += len(new_objects)
                logger.info(
                    f"üîπ –ü–∞–∫–µ—Ç {i // batch_size + 1}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(new_objects)}, –ø—Ä–æ–ø—É—â–µ–Ω–æ {len(chunk) - len(new_objects)}")

        logger.info(f"üéâ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω: –≤—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {added}, –ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped}")

    async def _get_existing_profiles(self, session: AsyncSession, profiles: list[str]) -> set:
        result = await session.execute(select(Supplier.wb_profile).where(Supplier.wb_profile.in_(profiles)))
        return set(row[0] for row in result.all())

    async def update_missing_inns_once(self, api: SellerParserAPI, batch_size: int = 100) -> bool:
        async with self.db.session() as session:
            stmt = (
                select(Supplier)
                .where(Supplier.wb_profile.is_not(None), Supplier.inn.is_(None))
                .limit(batch_size)
            )
            result = await session.execute(stmt)
            suppliers_batch = result.scalars().all()

            if not suppliers_batch:
                logger.info("üü¢ –í—Å–µ –ò–ù–ù —É–∂–µ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã.")
                return False

            links = [s.wb_profile for s in suppliers_batch if s.wb_profile]

            try:
                inns_data = await api.get_inns_by_links(links)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –ò–ù–ù: {e}")
                return False

            link_to_inn = {entry['link']: entry['inn'] for entry in inns_data if entry.get('inn')}

            updated = 0
            for supplier in suppliers_batch:
                inn = link_to_inn.get(supplier.wb_profile)
                if inn:
                    supplier.inn = inn
                    updated += 1

            await session.commit()
            logger.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ {updated} –ò–ù–ù –∏–∑ {len(suppliers_batch)}")
            return True
